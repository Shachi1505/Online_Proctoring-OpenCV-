{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abe27858",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 122\u001b[0m\n\u001b[0;32m    120\u001b[0m         blink_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    121\u001b[0m         blink_times\u001b[38;5;241m.\u001b[39mappend(time\u001b[38;5;241m.\u001b[39mtime())\n\u001b[1;32m--> 122\u001b[0m         winsound\u001b[38;5;241m.\u001b[39mBeep(\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m150\u001b[39m)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Gaze detection\u001b[39;00m\n\u001b[0;32m    125\u001b[0m gaze_ratio \u001b[38;5;241m=\u001b[39m get_gaze_direction(landmarks, LEFT_EYE, LEFT_IRIS, w, h)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import time\n",
    "import winsound\n",
    "import numpy as np\n",
    "\n",
    "# Setup MediaPipe\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True)\n",
    "\n",
    "# Constants\n",
    "LEFT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "RIGHT_EYE = [33, 160, 158, 133, 153, 144]\n",
    "LEFT_IRIS = [474, 475, 476, 477]\n",
    "RIGHT_IRIS = [469, 470, 471, 472]\n",
    "\n",
    "EAR_THRESHOLD = 0.23\n",
    "DROWSINESS_BLINK_THRESHOLD = 20\n",
    "GAZE_LEFT_LIMIT = 0.15\n",
    "GAZE_RIGHT_LIMIT = 0.85\n",
    "SUSPICIOUS_GAZE_LIMIT = 6  # max allowed gaze away events per minute\n",
    "\n",
    "# 3D model points of facial landmarks (nose tip, chin, left eye, right eye, left mouth, right mouth)\n",
    "FACE_3D_POINTS = np.array([\n",
    "    (0.0, 0.0, 0.0),          # Nose tip\n",
    "    (0.0, -63.6, -12.5),      # Chin\n",
    "    (-43.3, 32.7, -26.0),     # Left eye left corner\n",
    "    (43.3, 32.7, -26.0),      # Right eye right corner\n",
    "    (-28.9, -28.9, -24.1),    # Left mouth corner\n",
    "    (28.9, -28.9, -24.1)      # Right mouth corner\n",
    "], dtype=np.float64)\n",
    "\n",
    "# Corresponding 2D landmark indices in MediaPipe\n",
    "FACE_2D_IDXS = [1, 152, 263, 33, 287, 57]\n",
    "\n",
    "# Helper functions\n",
    "def euclidean(p1, p2):\n",
    "    return math.hypot(p2[0] - p1[0], p2[1] - p1[1])\n",
    "\n",
    "def eye_aspect_ratio(landmarks, eye_points, w, h):\n",
    "    coords = [(int(landmarks[i].x * w), int(landmarks[i].y * h)) for i in eye_points]\n",
    "    A = euclidean(coords[1], coords[5])\n",
    "    B = euclidean(coords[2], coords[4])\n",
    "    C = euclidean(coords[0], coords[3])\n",
    "    return (A + B) / (2.0 * C)\n",
    "\n",
    "def get_gaze_direction(landmarks, eye_idx, iris_idx, w, h):\n",
    "    eye_coords = [(int(landmarks[i].x * w), int(landmarks[i].y * h)) for i in eye_idx]\n",
    "    iris_coords = [(int(landmarks[i].x * w), int(landmarks[i].y * h)) for i in iris_idx]\n",
    "    eye_left = eye_coords[0][0]\n",
    "    eye_right = eye_coords[3][0]\n",
    "    iris_center_x = sum([p[0] for p in iris_coords]) // len(iris_coords)\n",
    "    position_ratio = (iris_center_x - eye_left) / (eye_right - eye_left + 1e-6)\n",
    "    return position_ratio\n",
    "\n",
    "def get_head_pose(landmarks, w, h):\n",
    "    image_points = np.array([\n",
    "        (landmarks[i].x * w, landmarks[i].y * h) for i in FACE_2D_IDXS\n",
    "    ], dtype=np.float64)\n",
    "    # Camera internals\n",
    "    focal_length = w\n",
    "    center = (w / 2, h / 2)\n",
    "    camera_matrix = np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float64)\n",
    "    dist_coeffs = np.zeros((4, 1))\n",
    "    success, rotation_vector, translation_vector = cv2.solvePnP(\n",
    "        FACE_3D_POINTS, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE\n",
    "    )\n",
    "    if not success:\n",
    "        return None\n",
    "    # Convert rotation vector to Euler angles\n",
    "    rmat, _ = cv2.Rodrigues(rotation_vector)\n",
    "    proj_matrix = np.hstack((rmat, translation_vector))\n",
    "    _, _, _, _, _, _, euler_angles = cv2.decomposeProjectionMatrix(proj_matrix)\n",
    "    yaw = euler_angles[1][0]  # Yaw (left/right)\n",
    "    return yaw\n",
    "\n",
    "# State variables\n",
    "blink_count = 0\n",
    "blink_times = []\n",
    "gaze_away_times = []\n",
    "blink_state = False\n",
    "gaze_warning_active = False  # To avoid repeated beeps\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w = frame.shape[:2]\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb)\n",
    "\n",
    "    suspicious_warning = False\n",
    "    drowsy_warning = False\n",
    "    head_turn_warning = False\n",
    "    face_not_found = False\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        landmarks = results.multi_face_landmarks[0].landmark\n",
    "\n",
    "        # Blink detection\n",
    "        left_ear = eye_aspect_ratio(landmarks, LEFT_EYE, w, h)\n",
    "        right_ear = eye_aspect_ratio(landmarks, RIGHT_EYE, w, h)\n",
    "        avg_ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "        if avg_ear < EAR_THRESHOLD:\n",
    "            if not blink_state:\n",
    "                blink_state = True\n",
    "        else:\n",
    "            if blink_state:\n",
    "                blink_state = False\n",
    "                blink_count += 1\n",
    "                blink_times.append(time.time())\n",
    "                winsound.Beep(1000, 150)\n",
    "\n",
    "        # Gaze detection\n",
    "        gaze_ratio = get_gaze_direction(landmarks, LEFT_EYE, LEFT_IRIS, w, h)\n",
    "        if gaze_ratio < GAZE_LEFT_LIMIT or gaze_ratio > GAZE_RIGHT_LIMIT:\n",
    "            gaze_away_times.append(time.time())\n",
    "\n",
    "        # Head pose detection\n",
    "        yaw = get_head_pose(landmarks, w, h)\n",
    "        if yaw is not None and abs(yaw) > 25:  # threshold in degrees\n",
    "            head_turn_warning = True\n",
    "    else:\n",
    "        face_not_found = True\n",
    "\n",
    "    # Clean old timestamps\n",
    "    now = time.time()\n",
    "    blink_times = [t for t in blink_times if now - t < 60]\n",
    "    gaze_away_times = [t for t in gaze_away_times if now - t < 60]\n",
    "    blink_rate = len(blink_times)\n",
    "    gaze_away_count = len(gaze_away_times)\n",
    "\n",
    "    # Display text\n",
    "    cv2.putText(frame, f\"Blinks: {blink_count}\", (30, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Rate: {blink_rate}/min\", (30, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (100, 255, 255), 2)\n",
    "\n",
    "    if face_not_found:\n",
    "        # Show face not detected message at the top center, suppress all other warnings\n",
    "        text = \"Face not detected!\"\n",
    "        textsize = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1.2, 3)[0]\n",
    "        textX = (frame.shape[1] - textsize[0]) // 2\n",
    "        cv2.putText(frame, text, (textX, 60), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "        gaze_warning_active = False  # Reset gaze warning state\n",
    "    else:\n",
    "        y_offset = 110\n",
    "        if blink_rate > DROWSINESS_BLINK_THRESHOLD:\n",
    "            drowsy_warning = True\n",
    "            cv2.putText(frame, \"WARNING: Drowsiness Detected!\", (30, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 3)\n",
    "            y_offset += 40\n",
    "\n",
    "        if gaze_away_count > SUSPICIOUS_GAZE_LIMIT:\n",
    "            suspicious_warning = True\n",
    "            cv2.putText(frame, \"Please look on screen\", (30, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "            if not gaze_warning_active:\n",
    "                winsound.Beep(1200, 200)\n",
    "                gaze_warning_active = True\n",
    "            y_offset += 40\n",
    "        else:\n",
    "            gaze_warning_active = False  # Reset when not in warning\n",
    "\n",
    "        if head_turn_warning:\n",
    "            cv2.putText(frame, \"Suspicious head turn detected!\", (30, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Exam_Checker\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
